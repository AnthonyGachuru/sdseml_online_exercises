{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Session 5:\n",
    "## Growing Causal Trees \n",
    "### - *Causal Forests and Generalized Random Forests*\n",
    "\n",
    "*Andreas Bjerre-Nielsen*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. Growing causal trees\n",
    "  - [Recap on Random Forest](Recap-on-Random-Forest)\n",
    "  - [Causal Forest](#Causal-Forest)\n",
    "  - [Generalized Random Forest](#Generalized-Random-Forest) (GRF)\n",
    "1. Applying GRF \n",
    "  - [In-class research: heterogeneous treatment effects](#In-class-research:-heterogeneous-treatment-effects)\n",
    "  - [Using R within Python](Using-R-within-Python)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap on Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The  forest full of trees\n",
    "\n",
    "What is the difference between a Decision Tree and a Random Forest?\n",
    "\n",
    "- decision tree: iteratively splits data into subset based on some parameter (often entropy or similar loss function), and calculates the mean outcome in each leaf (end of splits).\n",
    "- random forest: Collection of decision trees \n",
    "    - subsets of data by bootstap (sampling with replcement) \n",
    "    - subset of features\n",
    "    - by aggregeating over many trees (that are uncoralted) gives a more robust estimation and allows us to find a better pattern.\n",
    "\n",
    "<center><img src='https://p1.pxfuel.com/preview/386/193/136/forest-of-rugen-trees-beech-wood-nature-deciduous-forest-rest-national-park.jpg' alt=\"Drawing\" style=\"width: 680px;\"/></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## A special tree \n",
    "\n",
    "So what distinguishes a Causal Tree from a Decision Tree?\n",
    "\n",
    "- Causal tree estimates partition of data where treatment effects can be computed locaclly. \n",
    "- In order to have valid estimates we need to **honesty** of trees, by estimating partitions and treatment effects on different subsets of the data. \n",
    "    - analogy to train/test split\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center><img src='https://live.staticflickr.com/2880/33000342484_8681f68a01_b.jpg' alt=\"Drawing\" style=\"width: 600px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A tradeoff in structure of heterogeneity\n",
    "\n",
    "\n",
    "Two approaches? \n",
    "\n",
    "- Data driven heterogeneity\n",
    "  - Based on causal trees etc. \n",
    "- A priori sensible heterogeneity \n",
    "  - e.g. gender, socioeconomic, ethnicity\n",
    "  - We use a regression model and have an interaction with a desired variable\n",
    "\n",
    "When to choose which?\n",
    "- Choose data drive hetrogenitey for policy where you want to maximize impact given data (no theory).\n",
    "- if we want to test whether certain subgroups are acversely affected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Limitations of Decision Trees \n",
    "\n",
    "\n",
    "Random forests are nice but no asymptotic normality of prediction.\n",
    "\n",
    "- Crucial for inference! (corresponds to MLR6 in Econometrics 1)\n",
    "\n",
    "- Also holds for causal trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random forest for inference and treatment effecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Causal  Trees\n",
    "\n",
    "The goal of causal trees is to establish unbiased, consistent estimates of heterogeneous treatment effects\n",
    "- also known as conditional average treatment effects (**CATE**)\n",
    "- the effect size is denoted $\\hat{\\tau}(x)$;\n",
    "- standard tools for inference, e.g. using statistical tests locally\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Causal Forest \n",
    "\n",
    "What is the output from the decisions trees? Each tree produces a partitioning of the feature space $X$. Example of three trees:\n",
    "\n",
    "<center><img src='partitions.JPG' alt=\"Drawing\" style=\"width: 1000px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Double Sample Trees \n",
    "\n",
    "For Causal Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# - first half ($\\mathcal{J}$, $|\\mathcal{J}|=\\lceil s / 2\\rceil$) (if **s** is uneven you round **up** here) \n",
    "  - training Decision Tree\n",
    "    - minimize adjusted MSE \n",
    "    - require at least $k$ observations for both treatment and control in all leaves of $\\mathcal{I}$-sample\n",
    "- other half  ($\\mathcal{I}$, $|\\mathcal{I}|=\\lfloor s / 2\\rfloor$) (if **s** is uneven you round **down** here) \n",
    "  - estimating treatment effects, $\\hat{\\tau}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Double Sample Trees (2)\n",
    "\n",
    "For Regression Trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- first half ($\\mathcal{J}$, $|\\mathcal{J}|=\\lceil s / 2\\rceil$)\n",
    "  - training Decision Tree\n",
    "    - minimize MSE / Gini etc.\n",
    "    - require at least $k$ observations in all leaves of $\\mathcal{I}$-sample\n",
    "- other half  ($\\mathcal{I}$, $|\\mathcal{I}|=\\lfloor s / 2\\rfloor$)\n",
    "  - estimating outcome, $\\hat{\\mu}(x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Quiz:** How is this different from normal Decision Trees for regression problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- Unlike normal decision trees outcomes are estimated honestly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Main results: econometric properties (1)\n",
    "\n",
    "\n",
    "\n",
    "[Wager and Athey (2017)](https://doi.org/10.1080/01621459.2017.1319839) show \n",
    " - We can estimate the variance of CATE\n",
    " - $\\hat{V}_{IJ}(x)=\\frac{n-1}{n}\\left(\\frac{n}{n-s}\\right)^{2} \\sum_{i=1}^{n} \\operatorname{Cov}_{*}\\left[\\hat{\\tau}_{b}^{*}(x), N_{i b}^{*}\\right]^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Main results: econometric properties (2)\n",
    "\n",
    "From Theorem 4.1 in [Wager and Athey (2017)](https://doi.org/10.1080/01621459.2017.1319839)\n",
    "\n",
    "- The conditional average treatment estimates are unbiased and consistent\n",
    "  - unbiased: no systematic error of measurement\n",
    "  - consistency: with more data our estimate approaches true value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Moreover, we can do inference:\n",
    "  - The variance estimator $\\hat{V}_{IJ}(x)$ is consistent.\n",
    "  - Treatment effect estimates are asymptotic normal and unbiased\n",
    "    - $(\\hat{\\tau}(x)-\\tau(x)) / \\sqrt{\\operatorname{Var}[\\hat{\\tau}(x)]} \\Rightarrow \\mathcal{N}(0,1)$\n",
    "    - therefore we can do inference! Because we know the distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Caveat: only works for evaluating treatment effects in one point $x$! Do not perform multiple tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Useful forests\n",
    "\n",
    "Two more procedures\n",
    "**(the target is the treatment indicator!! Also last lesson.)**\n",
    "\n",
    "1. Double Sampled Trees\n",
    "  - using Regression trees for predicting outcome (=$\\hat{\\mu}(x)$)\n",
    "1. Propensity Trees\n",
    "  -  using propensity trees for propensity score matching\n",
    " \n",
    " \n",
    "if we want to use this method on observable, we have to be very persuasive that the data is unconfounded (unless it is an expirement). Which is quite difficult. \n",
    "\n",
    "**The main point is honesty! Splitting the data. One for testing and one for estimating **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is the shared procedure? \n",
    "- Each tree is estimated using repeated subsampling (**no replacement**)\n",
    "  - Constrast to bootstrap aggregation in random forest (sample **with replacment**)\n",
    "- Random subsample of features  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More results \n",
    "\n",
    "[Wager and Athey (2017)](https://doi.org/10.1080/01621459.2017.1319839) show that the same properties of Double Sample Trees using causal trees also hold analogously for regression trees. \n",
    "\n",
    "**important for exam! \n",
    "What is the difference between a double sample tree and normal forest: Then what is written below is the answer.**\n",
    "\n",
    "- Random forests  have the property of being asymptotic normal and can thus be used for inference\n",
    "- Similar intuition as idea of nested CV where we could do inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To sum up**\n",
    "\n",
    "**Random Forest:**\n",
    "    -bootstrp sample: For both estimating and partitioning. \n",
    "    \n",
    "**Double Sample Trees**\n",
    "    - Subsample of Partition Y\n",
    "    - Subsample for *something* I  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulation experiment\n",
    "\n",
    "[Wager,  and Athey (2017)](https://doi.org/10.1214/18-aos1709) compare causal forest to nearest neighbor methods \n",
    "- random forest is kind of local nearest neighbor estimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulation (1) \n",
    "\n",
    "- simulation setup: no treatment effect, only confounding factors\n",
    "- method: propensity trees \n",
    "- comparison of estimated treatment effects  \n",
    "    - lower MSE and better coverage\n",
    "    - coverage falls for increasing number of variables $d$\n",
    "\n",
    "<center><img src='cf_tab1.JPG' alt=\"Drawing\" style=\"width: 700px;\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulation (2) \n",
    "\n",
    "- setup: heterogeneous treatment effect, **no** confounding factors\n",
    "\n",
    "- comparison of estimated treatment effects\n",
    "    - lower MSE and better coverage\n",
    "    - coverage (how often does it actually hits the true estimate) falls for increasing number of variables $d$\n",
    "\n",
    "<center><img src='cf_tab2.JPG' alt=\"Drawing\" style=\"width: 700px;\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Meta learners for heterogeneous treatment effects \n",
    "\n",
    "The idea of estimating hetogenious treatment effects is highly studied in econometrics right now. Such as: \n",
    "\n",
    "Other procedures have been investigated\n",
    "\n",
    "- [Künzel et al. (2019)](https://doi.org/10.1073/pnas.1804597116) investigates more general class of prediction tools for partitioning data using \n",
    "\n",
    "  - Lower EMSE in many cases relative to causal forest and BART (Bayesian tree based method)\n",
    "  \n",
    "- [Nie and Wager (2017)](https://arxiv.org/pdf/1712.04912.pdf) investigates another class of methods called R-learners that leverages a smart representation of CATE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Round-up causal forest\n",
    "\n",
    "Summary of [Wager and Athey (2017)](https://doi.org/10.1080/01621459.2017.1319839) \n",
    "- builds on Causal Trees method\n",
    "- strong econometric properties\n",
    "  - unbiased and consistent\n",
    "  - asymptotic normality given $x$\n",
    "      - causal and regression forest allows inference!\n",
    "- problem: \n",
    "  - must choose focus \n",
    "    - unconfounding (propensity) or \n",
    "    - estimate CATE\n",
    "  - coverage was not good, especially for higher $d$!\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generalized Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A higher aim\n",
    "\n",
    "Causal forests are pretty cool. Can we use our honest procedure more generally? \n",
    "\n",
    "Something that can both uncounfound our data and estimate hetroganous treatment effects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Estimate any quantity $\\theta(x)$ identified via local moment conditions, e.g.\n",
    "  - simultaneously unconfound and find heterogeneity?\n",
    "  - find heterogeneous treatment effects from IV estimation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Different purpose\n",
    "\n",
    "How does this look?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The general moment conditions\n",
    "    - $\\mathbb{E}\\left[\\psi_{\\theta(x), \\nu(x)}\\left(O_{i}\\right) | X_{i}=x\\right]=0, \\quad \\forall x.$\n",
    "    \n",
    "- Where $\\psi$  estimating function, maps parameters and data into moment equations\n",
    "  - Parameters\n",
    "    - $\\theta$ parameter we want estimate \n",
    "    - $\\nu$ is nuisance we want to \"partial out\"\n",
    "  - Data     \n",
    "    - $O_i$ main objects we are interested in modelling, e.g. $Y_i, D_i$\n",
    "    - $X_i$ covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Different purpose (2)\n",
    "\n",
    "What is a moment condition?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Similiar to solution to first order condition\n",
    "- More general - can incorporate extra restrictions (e.g. unconfounding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Different purpose (3)\n",
    "\n",
    "Suppose we want to estimate treatment effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Functional form: $\\psi_{\\beta(x),c(x)}=Y_i-\\beta(x)W_i-c(x)$ where\n",
    "  - $\\beta$ is treatment effect\n",
    "  - $c$ is nuisance parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using a kernel\n",
    "\n",
    "Kernel methods can be used to unconfound and compute heterogeneous effects simulateneously\n",
    "\n",
    "\n",
    "- Problem how to decide weights?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<center><img src='partitions_weights.JPG' alt=\"Drawing\" style=\"width: 1000px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Generalized Random Forest\n",
    "\n",
    "[Athey, Wager, Tibshirani (2019)](https://doi.org/10.1214/18-aos1709) show that kernel weights can be estimated using forest methods\n",
    "\n",
    "- can be adapted for different purposes\n",
    "  - quantile regression\n",
    "  - heterogeneous treatment effects\n",
    "  - instrumental variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Generalized Random Forest (2)\n",
    "\n",
    "[Athey, Wager, Tibshirani (2019)](https://doi.org/10.1214/18-aos1709) use a procedure as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use estimating equation, $\\psi$ to estimate tree splits iteratively on subsample. \n",
    "2. View forests as a weights of similar neighbors\n",
    "    - Amount of partitions where observations \n",
    "  \\begin{equation}\\alpha_i(x)=\\frac{1}{B}\\sum_{b=1}\\frac{\\mathbb{1}(X_i\\in L_b(X)}{|L_b(x)|}\\end{equation}\n",
    "3. Re-estimate $\\psi$ using weights on entire sample.\n",
    "\n",
    "Difference from Causal Forest - trees are used for constructing weights!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In-class research: heterogeneous treatment effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The student as a researcher\n",
    "\n",
    "We will try to make a collaborative effort in doing a research project. \n",
    "\n",
    "The primary goal is to learn how to apply the methods. Our effort may turn into research.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The task\n",
    "\n",
    "Work alone or in pairs.\n",
    "\n",
    "1. Find a research paper that runs an experiment, either field or lab. Requirements for paper:\n",
    "  - There are is at least one or more covariates for each treated unit (e.g. gender if individuals).\n",
    "  - There is experimental data is available. You may look in the dataverse at Harvard or papers from experimental economics etc.\n",
    "1. Make a function that loads and structure the data in Python. The output should contain:\n",
    "  - Outcomes, $y$ a vector with $n$-observations \n",
    "  - Treatments, $D$ a vector with $n$-observations with $0,1$  \n",
    "  - Covariates, $X$ a matrix with $n\\times k$ dimensions\n",
    "1. Try to replicate the results in terms of computing ATE or ATT.\n",
    "1. Use `grf` to compute average treatment effects and heterogeneous treatment effects.\n",
    "  - Hint: you can use the `grf` tutorial [here](https://grf-labs.github.io/grf/articles/grf.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using R within Python\n",
    "## Leveraging the rpy2 package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installing R in Anaconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!conda install -c r rpy2 -y\n",
    "!conda install -c r r-irkernel -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import R in python\n",
    "\n",
    "If the code below fails, check out the guidance on adding PATH variables [for Linux or Mac](https://stackoverflow.com/questions/51486081/install-and-use-rpy2-using-conda-so-that-it-uses-default-r-installation-in-us) and [for Windows](https://anaconda.zendesk.com/hc/en-us/articles/360023857134-Setting-up-rpy2-on-Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as robjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installing R from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inbarshamir/anaconda3/lib/python3.7/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: also installing the dependencies ‘ps’, ‘processx’, ‘callr’, ‘backports’, ‘desc’, ‘pkgbuild’, ‘rprojroot’, ‘ellipsis’, ‘pkgload’, ‘rlang’, ‘colorspace’, ‘testthat’, ‘farver’, ‘munsell’, ‘lifecycle’, ‘zoo’, ‘gtable’, ‘isoband’, ‘scales’, ‘DiceKriging’, ‘lmtest’, ‘sandwich’, ‘RcppEigen’\n",
      "\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# import rpy2's package module\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "# import R's utility package\n",
    "utils = rpackages.importr('utils')\n",
    "\n",
    "# select a mirror for R packages\n",
    "utils.chooseCRANmirror(ind=1) # select the first mirror in the list\n",
    "\n",
    "# R package names\n",
    "packnames = ('ggplot2', 'hexbin', 'grf')\n",
    "\n",
    "# R vector of strings\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "\n",
    "# Selectively install what needs to be install.\n",
    "# We are fancy, just because we can.\n",
    "names_to_install = [x for x in packnames if not rpackages.isinstalled(x)]\n",
    "if len(names_to_install) > 0:\n",
    "    utils.install_packages(StrVector(names_to_install))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importing R package from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "RRuntimeError",
     "evalue": "Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) : \n  object 'vI' not found\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-bd29846d898e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#grf = importr('grf')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/Users/inbarshamir/anaconda3/lib/R/library\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/packages.py\u001b[0m in \u001b[0;36mimportr\u001b[0;34m(name, lib_loc, robject_translations, signature_translation, suppress_messages, on_conflict, symbol_r2python, symbol_check_after, data)\u001b[0m\n\u001b[1;32m    451\u001b[0m     if _package_has_namespace(rname, \n\u001b[1;32m    452\u001b[0m                               _system_file(package = rname)):\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_namespace_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mexported_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_namespace_exports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) : \n  object 'vI' not found\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "#grf = importr('grf')\n",
    "\n",
    "grf = importr('grf', lib_loc=\"/Users/inbarshamir/anaconda3/lib/R/library\")\n",
    "\n",
    "\n",
    "#base = importr('base')\n",
    "print(base.R_home())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rural</th>\n",
       "      <th>Quota</th>\n",
       "      <th>Age</th>\n",
       "      <th>Female</th>\n",
       "      <th>Edu</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Relig</th>\n",
       "      <th>BiasPol</th>\n",
       "      <th>BiasRights</th>\n",
       "      <th>...</th>\n",
       "      <th>CClistsen</th>\n",
       "      <th>PolInt</th>\n",
       "      <th>PolDisc</th>\n",
       "      <th>CCcontact</th>\n",
       "      <th>WomUnfair1</th>\n",
       "      <th>WomUnfair2</th>\n",
       "      <th>WomUnfair3</th>\n",
       "      <th>Under25</th>\n",
       "      <th>Under20</th>\n",
       "      <th>Under30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.00000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>996.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>595.656627</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.262048</td>\n",
       "      <td>41.747992</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.187751</td>\n",
       "      <td>2.720884</td>\n",
       "      <td>3.846386</td>\n",
       "      <td>3.054217</td>\n",
       "      <td>2.554217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.674699</td>\n",
       "      <td>3.109438</td>\n",
       "      <td>2.040161</td>\n",
       "      <td>1.568273</td>\n",
       "      <td>2.018072</td>\n",
       "      <td>2.017068</td>\n",
       "      <td>2.269076</td>\n",
       "      <td>0.252008</td>\n",
       "      <td>0.105422</td>\n",
       "      <td>0.376506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>334.770820</td>\n",
       "      <td>0.43323</td>\n",
       "      <td>0.439970</td>\n",
       "      <td>18.662185</td>\n",
       "      <td>0.500251</td>\n",
       "      <td>1.617085</td>\n",
       "      <td>1.353353</td>\n",
       "      <td>0.601085</td>\n",
       "      <td>1.183247</td>\n",
       "      <td>1.312511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849831</td>\n",
       "      <td>1.133798</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.955470</td>\n",
       "      <td>0.959310</td>\n",
       "      <td>0.996834</td>\n",
       "      <td>0.991363</td>\n",
       "      <td>0.434384</td>\n",
       "      <td>0.307250</td>\n",
       "      <td>0.484753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>304.750000</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>601.500000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>875.250000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1189.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      Rural       Quota         Age      Female         Edu  \\\n",
       "count   996.000000  996.00000  996.000000  996.000000  996.000000  996.000000   \n",
       "mean    595.656627    0.75000    0.262048   41.747992    0.500000    3.187751   \n",
       "std     334.770820    0.43323    0.439970   18.662185    0.500251    1.617085   \n",
       "min       1.000000    0.00000    0.000000   18.000000    0.000000    1.000000   \n",
       "25%     304.750000    0.75000    0.000000   25.000000    0.000000    2.000000   \n",
       "50%     601.500000    1.00000    0.000000   37.000000    0.500000    3.000000   \n",
       "75%     875.250000    1.00000    1.000000   57.000000    1.000000    4.000000   \n",
       "max    1189.000000    1.00000    1.000000   91.000000    1.000000    9.000000   \n",
       "\n",
       "          Poverty       Relig     BiasPol  BiasRights  ...   CClistsen  \\\n",
       "count  996.000000  996.000000  996.000000  996.000000  ...  996.000000   \n",
       "mean     2.720884    3.846386    3.054217    2.554217  ...    1.674699   \n",
       "std      1.353353    0.601085    1.183247    1.312511  ...    0.849831   \n",
       "min      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "25%      1.000000    4.000000    2.000000    1.000000  ...    1.000000   \n",
       "50%      3.000000    4.000000    4.000000    3.000000  ...    1.000000   \n",
       "75%      4.000000    4.000000    4.000000    4.000000  ...    2.000000   \n",
       "max      5.000000    4.000000    4.000000    4.000000  ...    4.000000   \n",
       "\n",
       "           PolInt     PolDisc   CCcontact  WomUnfair1  WomUnfair2  WomUnfair3  \\\n",
       "count  996.000000  996.000000  996.000000  996.000000  996.000000  996.000000   \n",
       "mean     3.109438    2.040161    1.568273    2.018072    2.017068    2.269076   \n",
       "std      1.133798    0.761111    0.955470    0.959310    0.996834    0.991363   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      2.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "50%      4.000000    2.000000    1.000000    2.000000    2.000000    2.000000   \n",
       "75%      4.000000    3.000000    2.000000    3.000000    3.000000    3.000000   \n",
       "max      4.000000    3.000000    4.000000    4.000000    4.000000    4.000000   \n",
       "\n",
       "          Under25     Under20     Under30  \n",
       "count  996.000000  996.000000  996.000000  \n",
       "mean     0.252008    0.105422    0.376506  \n",
       "std      0.434384    0.307250    0.484753  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      1.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/inbarshamir/Dropbox/Msc/Econ & ML/Ex. and Solutions/LesothoAB2012.csv')\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
