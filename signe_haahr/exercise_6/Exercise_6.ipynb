{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 - Linear ML for Econometrics\n",
    "\n",
    "In this exercise set, we will work with linear ML methods that can give unbiased estimates when the number of covariates is large. We will once again set up simulated data to clearly see any issues with the methods we apply. The exercises follow the approach laid out in [Chernozhukov et al](https://arxiv.org/pdf/1501.03185.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The following code simulates two datasets, one to use with the auxilliary regression \n",
    ">$$ \\tag{aux}\n",
    "d_i = x_i'\\gamma_0 + z_i' \\Pi_0 + u_i\n",
    "$$\n",
    ">and one to use in the main equation\n",
    ">$$ \\tag{main}\n",
    "y_i = \\alpha_0 d_i + x_i' \\delta_0 + \\nu_i\n",
    "$$\n",
    "Unlike in the paper, we include covariates in the main equation. We will handle them in a later question. In this setup $u_i$ and $\\nu_i$ are correlated, meaning the relation between $d_i$ and $y_i$ is not identified via OLS. Instead we will use $z_i$ to induce exogenous variation in $d_i$, which is unrelated to the error terms. This variation can be used to identify $\\alpha_0$.\n",
    ">\n",
    "> **Ex 6.1.1.**  Rewrite the below code to define a function `simulate(n, m, k, plot)`, where plot is a boolean indicating whether the density plot should be drawn or not. Your function should return all the matrices and vectors required in the regression equations, including parameters and errors.\n",
    "\n",
    "```\n",
    "n = 1000  # Number of observations\n",
    "m = 1500    # Number of potential instruments\n",
    "k = 10    # Number of covariates\n",
    "\n",
    "cov = 5\n",
    "errors = np.random.multivariate_normal(mean = [0,0], cov = [[cov, cov], [cov, cov]], size = n)\n",
    "h = sns.jointplot(errors[:,0], errors[:,1], kind = 'kde')\n",
    "h.set_axis_labels('$\\\\nu$', '$\\epsilon$', fontsize=16)\n",
    "\n",
    "z = np.random.normal(size = (n,m))\n",
    "x = np.random.normal(size = (n,k))\n",
    "\n",
    "# Auxilliary equation\n",
    "nu = errors[:,0]\n",
    "Pi = np.array([5] + [x if np.random.uniform() > 0.9 else 0 for x in np.random.uniform(low = -2, high = 5, size = m - 1)])\n",
    "gamma = np.array([5] + [x if np.random.uniform() > 0.9 else 0 for x in np.random.uniform(low = -2, high = 5, size = k - 1)])\n",
    "\n",
    "d = z @ Pi + x @ gamma + nu\n",
    "\n",
    "# Main equation\n",
    "u = errors[:,1]\n",
    "delta = np.array([5] + [x  if np.random.uniform() > 0.9 else 0 for x in np.random.uniform(low = -2, high = 5, size = k - 1)])\n",
    "alpha = np.random.uniform(1,2)\n",
    "\n",
    "y = alpha * d  + x @ delta + u\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Your solution here]\n",
    "\n",
    "def simulate(n, m, k, plot = False):\n",
    "    cov = 5\n",
    "    errors = np.random.multivariate_normal(mean = [0,0], cov = [[cov, cov], [cov, cov]], size = n)\n",
    "\n",
    "    z = np.random.normal(size = (n,m))\n",
    "    x = np.random.normal(size = (n,k))\n",
    "\n",
    "    # Auxilliary equation\n",
    "    nu = errors[:,0]\n",
    "    Pi = np.array([5] + [x if np.random.uniform() > 0.9 else 0 for x in np.random.uniform(low = -2, high = 5, size = m - 1)])\n",
    "    gamma = np.array([5] + [x if np.random.uniform() > 0.9 else 0 for x in np.random.uniform(low = -2, high = 5, size = k - 1)])\n",
    "\n",
    "    d = z @ Pi + x @ gamma + nu\n",
    "\n",
    "    # Main equation\n",
    "    u = errors[:,1]\n",
    "    delta = np.array([5] + [x  if np.random.uniform() > 0.9 else 0 for x in \n",
    "                            np.random.uniform(low = -2, high = 5, size = k - 1)])\n",
    "    alpha = np.random.uniform(1,2)\n",
    "\n",
    "    y = alpha * d  + x @ delta + u\n",
    "    \n",
    "    # Make density plot when asked for it\n",
    "    if plot == True:\n",
    "        h = sns.jointplot(errors[:,0], errors[:,1], kind = 'kde')\n",
    "        h.set_axis_labels('$\\\\nu$', '$\\epsilon$', fontsize=16)\n",
    "        plt.show()\n",
    "    \n",
    "    return [y, d, x, z, u, nu, alpha, delta, Pi, gamma]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.2:** Use your function to simulate a new dataset and regress the following OLS regression\n",
    ">$$\n",
    "y_i \\sim \\pi_0 + \\pi_1 d_i + \\gamma_i\n",
    "$$\n",
    "> where $\\gamma_i$ is a noise term. \n",
    ">\n",
    "> Repeat this procedure 1000 times in a for loop and store the true $\\alpha_0$ as well as the estimate $\\pi_1$ in two lists. Plot a histogram of the differences $\\alpha_0 - \\pi_1$. What does this tell you about the regression you just ran?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "From the historgram plotted below, I see that $\\pi_1$ is upward biased, since the difference between $\\pi_1$ and the true treatment effect, $\\alpha_0$, is always negative. This makes sense, since we're just trying to estimate the treatment effect using OLS with no covariates, but the treatment indicator, $d_i$, is correlated with the error term, $\\gamma_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.tools import add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Your solution here]\n",
    "\n",
    "# Initialise empty lists to fill out in loop\n",
    "alpha0 = []\n",
    "pi1 = []\n",
    "\n",
    "# Simualte data and regress OLS 1000 times\n",
    "for i in range(1000):\n",
    "    if i < 1000:\n",
    "        sim = simulate(n = 1000, m = 1500, k = 10)\n",
    "        alpha0.append(sim[6])\n",
    "        \n",
    "        y = sim[0]\n",
    "        d = sim[1]\n",
    "        d = sm.add_constant(d)\n",
    "        model = sm.OLS(y,d)\n",
    "        results = model.fit()\n",
    "        pi1.append(results.params[1])\n",
    "        \n",
    "    elif i == 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of the difference between the true effect and the biased effect estimated with OLS\n",
    "\n",
    "# I can't subtract the two because they're lists. So, I have to use a bit complicated method...\n",
    "diff = []\n",
    "zip_object = zip(alpha0, pi1)\n",
    "for list1_i, list2_i in zip_object:\n",
    "    diff.append(list1_i-list2_i)\n",
    "\n",
    "plt.hist(diff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.3:** Knowing the DGP an obvious solution would be to run an IV regression, instrumenting $d_i$ with $z_i$. Unfortunately there are $m=1500$ columns in $z_i$ and only $n=1000$ observations. Luckily, the way we have simulated our data only a small subset of the $z_i$'s actually influence $d_i$. The tricky part will be to pick out the right $z_i$'s.\n",
    ">\n",
    "> To begin with, simulate a new dataset and count the number of non-zero element in $\\Pi$ to verify that indeed only very few $z$'s matter for $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "There are 166 non-zero elements in $\\Pi$, which is relatively few out of 1500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Your solution here]\n",
    "sim_new = simulate(n = 1000, m = 1500, k = 10)\n",
    "pi = sim_new[8]\n",
    "print(np.count_nonzero(pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.4:** The _ideal_ instrument for $d_i$ is exactly the $z_i$'s which have non-zero coefficients, multiplied by the corresponding true simulated parameters in $\\Pi_0$. Having simulated the data ourselves, an easy way to compute this is to simply calculate\n",
    "> $$\n",
    "\\hat{d}^* = z \\cdot \\Pi_0\n",
    "$$\n",
    "> where $\\cdot$ is the dot product, written as `@` in numpy. In reality we cannot get this ideal instrument, because it would require regressing $d_i$ on all 500 variables with only 100 observations.  \n",
    ">\n",
    "> In a for loop over 1000 iterations, simulate new data, compute the ideal instrument $\\hat{d_i}$ and regress the second stage regression $y_i \\sim \\pi_0 + \\pi_1\\hat{d_i}$. Store the true $\\alpha_0$ and the estimate $\\hat{\\pi}_1$ in two lists. Finally draw a histogram of the differences $\\alpha_0 - \\hat{\\pi}_1$. How does your histogram look this time, is this expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "From the histogram plotted below, I see that the estimate of the treatment effect, $\\hat{\\pi_1}$, is now downward biased, since the difference between the true treatment effect and the estimate is positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Your solution here]\n",
    "\n",
    "# Initialise lists to fill in loop below\n",
    "alpha0 = []\n",
    "p1_hat = []\n",
    "\n",
    "# Simulate data and regress second stage with ideal instrument 1000 times\n",
    "for i in range(1000):\n",
    "    if i < 1000:\n",
    "        sim_new = simulate(n = 1000, m = 1500, k = 10)\n",
    "        alpha0.append(sim[6])\n",
    "        \n",
    "        # Compute ideal instrument for treatment, d\n",
    "        z = sim_new[3]\n",
    "        Pi = sim_new[8]\n",
    "        d_star = z @ Pi\n",
    "        \n",
    "        # Regress the second stage regression\n",
    "        y = sim[0]\n",
    "        d = sim[1]\n",
    "        d_star = sm.add_constant(d_star)\n",
    "        model = sm.OLS(y, d_star)\n",
    "        results = model.fit()\n",
    "        p1_hat.append(results.params[1])\n",
    "        \n",
    "    elif i == 1000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of the difference between the true effect and the biased effect estimated with OLS\n",
    "diff_new = []\n",
    "zip_object = zip(alpha0, p1_hat)\n",
    "for list1_i, list2_i in zip_object:\n",
    "    diff_new.append(list1_i-list2_i)\n",
    "\n",
    "plt.hist(diff_new)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.5:** The below class implements post-LASSO. A two-step procedure where first a LASSO model is used to identify relevant parameters, and then OLS is used to estimate parameter values on the remaining variables. Study the code, and understand as well as possible what is going on. \n",
    ">\n",
    "> What is stored in `relevant_x`?\n",
    "> \n",
    "> Why is the `predict` method so complicated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "- In `relevant_x` is the relevant covariates stored from the LASSO, which is a variable selection and regularization method. Besides the most relevant covariates from the LASSO, `relevant_x` also includes variables forced into the vector, which can be specified in the `force_include_idx` option in the `fit()` function. \n",
    "\n",
    "- The `predict` method is complicated because it accounts for three possible cases:\n",
    " 1. When no covariates/features are specified: It uses `relevant_x` for prediction\n",
    " 2. When as many covariates are specified in `X` as the number of variables in `relevant_x`: It uses `X` for prediction\n",
    " 3. When more covariates are specified in `X` than the number of variables in `relevant_x`: It uses the subset of `X` that is in `relevant_x`\n",
    "\n",
    " I actually don't understand, why there have to be three different scenarios, since it uses the variables included in `relevant_x` each time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostLasso:\n",
    "    def __init__(self, formula = None):\n",
    "        self.lasso_model = Lasso()\n",
    "        self.ols_model = None\n",
    "        self.relevant_x = None\n",
    "        self.subset_cols = None\n",
    "        self.coefs = None\n",
    "        self.formula = formula\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'PostLasso({self.formula})'\n",
    "    \n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    \n",
    "    def fit(self, X, y, force_include_idx = None):\n",
    "        ''' Estimate a model using Post-LASSO\n",
    "        \n",
    "        X: X matrix (without intercept)\n",
    "        y: y vector\n",
    "        force_include_idx: column indexes that ALWAYS is\n",
    "            included in the OLS model, regardless of their\n",
    "            status in the LASSO stage.\n",
    "        '''\n",
    "        self.lasso_model = self.lasso_model.fit(X,y)\n",
    "        self.coefs = np.insert(self.lasso_model.coef_, 0, self.lasso_model.intercept_)\n",
    "        self.subset_cols = np.where(self.coefs != 0)[0]\n",
    "        \n",
    "        # This forces some variables to be part of the list of covariates. Typically, you would force the treatment \n",
    "        # indicator to be in the covariates\n",
    "        if force_include_idx is not None:\n",
    "            self.subset_cols = np.union1d(self.subset_cols, force_include_idx)\n",
    "        self.relevant_x = add_constant(X)[:,self.subset_cols]\n",
    "        self.ols_model = OLS(y, self.relevant_x).fit()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X = None):\n",
    "        ''' Predict using a fitted post-lasso model.\n",
    "        '''\n",
    "        if X is None:\n",
    "            return self.ols_model.predict(self.relevant_x)\n",
    "        if X.shape == self.relevant_x.shape:\n",
    "            return self.ols_model.predict(X)\n",
    "        return self.ols_model.predict(X[:,self.subset_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.6:** In this problem we will try to run through the post-lasso steps required to obtain an estimate of $\\alpha_0$. Since we are doing this in python we will not be able to set the lasso hyperparameter optimally for this kind of post-selection usage. There is a R package, developed especially to handle inference after lasso-selection, which you should use in practise. \n",
    ">\n",
    "> For now, do the following steps 1000 times, storing the true $\\alpha_0$ and estimate $\\hat{\\alpha_0}$:\n",
    ">\n",
    "> * 0. Simulate a new dataset.\n",
    "> * 1. Run a post-lasso regression of d on x and z, $d_i \\sim x_i'\\gamma + z_i' \\delta$, forcing the inclusion of $x_i$ in the OLS stage.\n",
    "> * 2. Run the second stage regression $y_i \\sim \\hat{d}_i + x_i' \\beta$ to recover $\\hat{\\alpha_0}$.\n",
    ">\n",
    "> How does this histogram compare to the naive one? How does it compare to the ideal one?\n",
    ">\n",
    "> _Hint:_ We follow the description given on page 19 [here](https://cran.r-project.org/web/packages/hdm/vignettes/hdm.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "I've tried to do the above, but I think my histogram looks weird. I thought I would find that the post-LASSO method resulted in an unbiased estimate of the treatment effect, but it looks like the estimate is biased. From the histogram, the estimate should be downwards biased and the bias/difference from the true treatment effect from the simulations are uniformly distributed from around 1.1 to 2.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Your solution here]\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Initialise lists to fill in loop below\n",
    "alpha0 = []\n",
    "alpha0_hat = []\n",
    "\n",
    "for i in range(1000):\n",
    "    if i < 1000:\n",
    "        # 0. Simulate \n",
    "        sim_new = simulate(n = 1000, m = 1500, k = 10)\n",
    "        alpha0.append(sim_new[6])\n",
    "\n",
    "        # 1. Run post-LASSO regrssion of d on X and z\n",
    "        # I have to concatenate X and z, since fit() only takes inputs X and y\n",
    "        X = np.concatenate((sim_new[2], sim_new[3]), axis=1)\n",
    "        d = sim_new[1]\n",
    "        force_include_idx = range(10)\n",
    "\n",
    "        post_lasso = PostLasso()\n",
    "        fit = post_lasso.fit(X, d, force_include_idx)\n",
    "        d_hat = post_lasso.predict()\n",
    "        \n",
    "        # 2. Run second stage regression of y on d and X\n",
    "        y = sim_new[0]\n",
    "        d_hat = sm.add_constant(d_hat) # Should I add constant??\n",
    "        \n",
    "        second_stage = sm.OLS(y, d_hat, X)\n",
    "        res = model.fit()\n",
    "        alpha0_hat.append(res.params[0])\n",
    "        \n",
    "    elif i == 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of difference between true and estimated treatment effect\n",
    "diff_new = []\n",
    "zip_object = zip(alpha0, alpha0_hat)\n",
    "for list1_i, list2_i in zip_object:\n",
    "    diff_new.append(list1_i-list2_i)\n",
    "\n",
    "plt.hist(diff_new)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
